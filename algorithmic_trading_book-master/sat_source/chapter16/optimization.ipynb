{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rates/Confusion Matrices:\n",
      "\n",
      "Logistic Regression:\n",
      "0.513\n",
      "[[ 69  67]\n",
      " [420 444]]\n",
      "\n",
      "LDA:\n",
      "0.513\n",
      "[[ 69  67]\n",
      " [420 444]]\n",
      "\n",
      "QDA:\n",
      "0.503\n",
      "[[ 83  91]\n",
      " [406 420]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ed/AlgorithmicTrading/trading/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC:\n",
      "0.513\n",
      "[[ 69  67]\n",
      " [420 444]]\n",
      "\n",
      "SVM (RBF Kernel):\n",
      "0.508\n",
      "[[ 13  16]\n",
      " [476 495]]\n",
      "\n",
      "Random Forest:\n",
      "0.489\n",
      "[[201 223]\n",
      " [288 288]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from create_lagged_series import create_lagged_series\n",
    "\n",
    "\n",
    "def run_models(X_train, X_test, y_train, y_test):\n",
    "    # Define the models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"LDA\": LDA(),\n",
    "        \"QDA\": QDA(),\n",
    "        \"Linear SVC\": LinearSVC(),\n",
    "        \"SVM (RBF Kernel)\": SVC(\n",
    "            C=1000000.0, gamma=0.0001, kernel='rbf'\n",
    "        ),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            n_estimators=1000, max_features='sqrt'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Iterate through the models\n",
    "    for name, model in models.items():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        # Output the hit-rate and the confusion matrix for each model\n",
    "        print(f\"{name}:\\n{model.score(X_test, y_test):.3f}\")\n",
    "        print(f\"{confusion_matrix(pred, y_test)}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a lagged series of the S&P500 US stock market index\n",
    "    snpret = create_lagged_series(\n",
    "        \"^GSPC\", datetime.datetime(2001, 1, 10),\n",
    "        datetime.datetime(2005, 12, 31), lags=5\n",
    "    )\n",
    "\n",
    "    # Use the prior two days of returns as predictor values, with direction as the response\n",
    "    X = snpret[[\"Lag1\", \"Lag2\"]]\n",
    "    y = snpret[\"Direction\"]\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.8, random_state=42\n",
    "    )\n",
    "\n",
    "    # Run models and print results\n",
    "    print(\"Hit Rates/Confusion Matrices:\\n\")\n",
    "    run_models(X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate/Confusion Matrix:\n",
      "0.544\n",
      "[[10  7]\n",
      " [50 58]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.408\n",
      "[[ 2  4]\n",
      " [70 49]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.528\n",
      "[[ 4  4]\n",
      " [55 62]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.520\n",
      "[[ 4  3]\n",
      " [57 61]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.512\n",
      "[[ 6  4]\n",
      " [57 58]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.480\n",
      "[[ 7  7]\n",
      " [58 53]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.624\n",
      "[[ 8  7]\n",
      " [40 70]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.464\n",
      "[[ 7 13]\n",
      " [54 51]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.560\n",
      "[[ 5  4]\n",
      " [51 65]]\n",
      "\n",
      "Hit Rate/Confusion Matrix:\n",
      "0.544\n",
      "[[ 5  5]\n",
      " [52 63]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from create_lagged_series import create_lagged_series\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a lagged series of the S&P500 US stock market index\n",
    "    snpret = create_lagged_series(\n",
    "        \"^GSPC\", datetime.datetime(2001, 1, 10),\n",
    "        datetime.datetime(2005, 12, 31), lags=5\n",
    "    )\n",
    "\n",
    "    # Use the prior two days of returns as predictor values, with direction as the response\n",
    "    X = snpret[[\"Lag1\", \"Lag2\"]]\n",
    "    y = snpret[\"Direction\"]\n",
    "\n",
    "    # Create a k-fold cross-validation object\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Use the kf object to create index arrays that state which elements have been retained for training\n",
    "    # and which elements have been retained for testing for each k-element iteration\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # In this instance only use the Radial Support Vector Machine (SVM)\n",
    "        print(\"Hit Rate/Confusion Matrix:\")\n",
    "        model = SVC(\n",
    "            C=1000000.0, gamma=0.0001, kernel='rbf',\n",
    "            tol=0.001, verbose=False\n",
    "        )\n",
    "\n",
    "        # Train the model on the retained training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make an array of predictions on the test set\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        # Output the hit-rate and the confusion matrix for each model\n",
    "        print(f\"{model.score(X_test, y_test):.3f}\")\n",
    "        print(f\"{confusion_matrix(pred, y_test)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^GSPC']: ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Max retries exceeded with url: /v8/finance/chart/%5EGSPC?period1=1389330000&period2=1703998800&interval=1d&includePrePost=False&events=div%2Csplits%2CcapitalGains&crumb=K2mhbswVpvr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6c94542e50>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.5 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m snpret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirection\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train/test split\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Set the parameters by cross-validation\u001b[39;00m\n\u001b[1;32m     24\u001b[0m tuned_parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     25\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m]}\n\u001b[1;32m     26\u001b[0m ]\n",
      "File \u001b[0;32m~/AlgorithmicTrading/trading/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/AlgorithmicTrading/trading/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2649\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2649\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AlgorithmicTrading/trading/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2305\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2302\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2309\u001b[0m     )\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.5 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from create_lagged_series import create_lagged_series\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a lagged series of the S&P500 US stock market index\n",
    "    snpret = create_lagged_series(\n",
    "        \"^GSPC\", datetime.datetime(2010, 1, 10),\n",
    "        datetime.datetime(2152, 12, 31), lags=5\n",
    "    )\n",
    "\n",
    "    # Use the prior two days of returns as predictor values, with direction as the response\n",
    "    X = snpret[[\"Lag1\", \"Lag2\"]]\n",
    "    y = snpret[\"Direction\"]\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    # Perform the grid search on the tuned parameters\n",
    "    model = GridSearchCV(SVC(), tuned_parameters, cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Optimized parameters found on the training set:\")\n",
    "    print(model.best_estimator_, \"\\n\")\n",
    "    \n",
    "    print(\"Grid scores calculated on training set:\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(f\"{mean:.3f} (+/-{std * 2:.03f}) for {params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
