{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 321 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /home/ed/AlgorithmicTrading/trading/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ed/AlgorithmicTrading/trading/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/home/ed/AlgorithmicTrading/trading/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rates/Confusion Matrices:\n",
      "\n",
      "LR:\n",
      "0.560\n",
      "[[ 35  35]\n",
      " [ 76 106]]\n",
      "\n",
      "LDA:\n",
      "0.560\n",
      "[[ 35  35]\n",
      " [ 76 106]]\n",
      "\n",
      "QDA:\n",
      "0.599\n",
      "[[ 30  20]\n",
      " [ 81 121]]\n",
      "\n",
      "LSVC:\n",
      "0.560\n",
      "[[ 35  35]\n",
      " [ 76 106]]\n",
      "\n",
      "RSVM:\n",
      "0.567\n",
      "[[ 10   8]\n",
      " [101 133]]\n",
      "\n",
      "RF:\n",
      "0.508\n",
      "[[49 62]\n",
      " [62 79]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_lagged_series(symbol, start_date, end_date, lags=5):\n",
    "    \"\"\"\n",
    "    This creates a Pandas DataFrame that stores the percentage returns of the adjusted closing value of\n",
    "    a stock obtained from Yahoo Finance, along with a number of lagged returns from the prior trading days\n",
    "    (lags defaults to 5 days). Trading volume, as well as the Direction from the previous day, are also included.\n",
    "    \"\"\"\n",
    "    # Obtain stock information from Yahoo Finance\n",
    "    ts = yf.download(symbol, start=start_date - datetime.timedelta(days=365), end=end_date)\n",
    "    \n",
    "    # Create the new lagged DataFrame\n",
    "    tslag = pd.DataFrame(index=ts.index)\n",
    "    tslag[\"Today\"] = ts[\"Adj Close\"]\n",
    "    tslag[\"Volume\"] = ts[\"Volume\"]\n",
    "    \n",
    "    # Create the shifted lag series of prior trading period close values\n",
    "    for i in range(0, lags):\n",
    "        tslag[f\"Lag{i+1}\"] = ts[\"Adj Close\"].shift(i+1)\n",
    "    \n",
    "    # Create the returns DataFrame\n",
    "    tsret = pd.DataFrame(index=tslag.index)\n",
    "    tsret[\"Volume\"] = tslag[\"Volume\"]\n",
    "    tsret[\"Today\"] = tslag[\"Today\"].pct_change() * 100.0\n",
    "    \n",
    "    # If any of the values of percentage returns equal zero, set them to\n",
    "    # a small number (stops issues with QDA model in Scikit-Learn)\n",
    "    tsret[\"Today\"].replace(to_replace=0, value=0.0001, inplace=True)\n",
    "    \n",
    "    # Create the lagged percentage returns columns\n",
    "    for i in range(0, lags):\n",
    "        tsret[f\"Lag{i+1}\"] = tslag[f\"Lag{i+1}\"].pct_change() * 100.0\n",
    "    \n",
    "    # Create the \"Direction\" column (+1 or -1) indicating an up/down day\n",
    "    tsret[\"Direction\"] = np.sign(tsret[\"Today\"])\n",
    "    tsret = tsret[tsret.index >= start_date]\n",
    "    \n",
    "    return tsret\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a lagged series of the S&P 500 US stock market index\n",
    "    snpret = create_lagged_series(\n",
    "        \"^GSPC\", datetime.datetime(2001, 1, 10),\n",
    "        datetime.datetime(2005, 12, 31), lags=5\n",
    "    )\n",
    "    \n",
    "    # Use the prior two days of returns as predictor values, with direction as the response\n",
    "    X = snpret[[\"Lag1\", \"Lag2\"]]\n",
    "    y = snpret[\"Direction\"]\n",
    "    \n",
    "    # The test data is split into two parts: Before and after 1st Jan 2005.\n",
    "    start_test = datetime.datetime(2005, 1, 1)\n",
    "    \n",
    "    # Create training and test sets\n",
    "    X_train = X[X.index < start_test]\n",
    "    X_test = X[X.index >= start_test]\n",
    "    y_train = y[y.index < start_test]\n",
    "    y_test = y[y.index >= start_test]\n",
    "    \n",
    "    # Create the (parametrized) models\n",
    "    print(\"Hit Rates/Confusion Matrices:\\n\")\n",
    "    models = [\n",
    "        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "        (\"LDA\", LDA()),\n",
    "        (\"QDA\", QDA()),\n",
    "        (\"LSVC\", LinearSVC(max_iter=10000)),\n",
    "        (\"RSVM\", SVC(\n",
    "            C=1000000.0, cache_size=200, coef0=0.0,\n",
    "            degree=3, gamma=0.0001, kernel='rbf',\n",
    "            max_iter=-1, probability=False, shrinking=True, tol=0.001, verbose=False)\n",
    "        ),\n",
    "        (\"RF\", RandomForestClassifier(\n",
    "            n_estimators=1000, criterion='gini', max_depth=None, \n",
    "            min_samples_split=2, min_samples_leaf=1, max_features='sqrt',  # Updated max_features\n",
    "            bootstrap=True, oob_score=False, n_jobs=-1, random_state=None, verbose=0)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Iterate through the models\n",
    "    for name, model in models:\n",
    "        # Train each of the models on the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make an array of predictions on the test set\n",
    "        pred = model.predict(X_test)\n",
    "        \n",
    "        # Output the hit-rate and the confusion matrix for each model\n",
    "        print(f\"{name}:\\n{model.score(X_test, y_test):.3f}\")\n",
    "        print(f\"{confusion_matrix(pred, y_test)}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
